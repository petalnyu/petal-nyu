<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>How Open AI’s Sora Tests Privacy, Creativity, and Policy</title>
    <link rel="stylesheet" href="../styles.css">
    <link rel="stylesheet" href="articles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Miriam+Libre:wght@400;700&display=swap" rel="stylesheet">
    <link rel="icon" type="image/png" href="../favicon/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="../favicon/favicon.svg" />
    <link rel="shortcut icon" href="../favicon/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="../favicon/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-title" content="PETAL" />
    <link rel="manifest" href="../favicon/site.webmanifest" />
</head>
<body class="article-page">
    <header>
        <nav>
            <div class="nav-container">
                <div class="logo">
                    <img src="../petal_logo.png" alt="PETAL logo">
                    <h1>petal</h1>
                </div>
                <ul class="nav-menu">
                    <li><a href="../index.html">Home</a></li>
                    <li><a href="../team.html">Meet the Team</a></li>
                    <li><a href="../events.html">Events</a></li>
                    <li><a href="../research.html" class="active">Research & Publications</a></li>
                </ul>
            </div>
        </nav>
    </header>
    <div class="article-container">
        <h1 class="article-title">How Open AI’s Sora Tests Privacy, Creativity, and Policy</h1>
        <h2 class="article-byline">By Tarunya Dharmarajan</h2>
        <p>In the realm of generative AI technologies, video generation has been one of the most remarkable yet simultaneously problematic innovations. Though it has become more popular in the past 4 years, AI video generation dates back to 2014, when the idea of generative adversarial networks (GANs) grew popular for generating audio, video, and imagery. This technology was relatively rudimentary, although it has since been improved upon and expanded. 
The most recent and revolutionary development in AI video generation is OpenAI’s Sora. Sora is advertised as having far more realistic imagery than any prior models, coupled with highly natural sound effects and dialogue. Like preceding models, Sora uses a text prompt from the user to generate a video. Video generation is done through the use of a diffusion transformer which compresses videos into simplified data, generates new videos, then decompresses it back to its full visual form. Sora scales this process to include more training data that helps the decompression of generated videos become clearer. 
</p>
    <center>
        <iframe width="350" height="200"
    src="https://openaiassets.blob.core.windows.net/$web/nf2/blog-final2/20250924_2154_New%20Video_simple_compose_01k5zkjk6cewmbdna01qtg293g.mp4">
    </iframe>
    <p>Video from <a href = "https://openai.com/index/sora-2/">OpenAI's launch of Sora</a></p>
    </center>

<p>While it is a remarkable feat in the world of innovation, it poses some serious challenges in real-world application, highlighting the need for more adaptive and comprehensive legislation. 
The model raises major concerns around the generation of disinformation via visual form, especially when it’s hard to detect in output from a hyperrealistic model like Sora. Much of this disinformation is circulated online, where it can be used to rapidly circulate political propaganda, falsified news headlines, and fabricated speech.</p>

 <center>
        <iframe width="350" height="200"
    src="https://openaiassets.blob.core.windows.net/$web/nf2/blog-final2/Copy%20of%2020250925_2005_New%20Video_simple_compose_01k61zpe8yfshs06fb6e768v88.mp4">
    </iframe>
    <p>Video from <a href = "https://openai.com/index/sora-2/">OpenAI's launch of Sora</a></p>
    </center>
        <p>Though this problem existed before with previous models, Sora’s heightened abilities to understand body movements and physics principles of motion make it far more believable than output from predecessors. Sora also has a feature called a “Cameo”, where the generated video can feature a person based on inputted reference videos. These features raise concerns about the futility of Hollywood and filmmaking as an art in the age of AI. Those in the film industry worry that Sora’s increased abilities to produce both audio and video may displace jobs in the field as producers attempt to cut costs. 
There are currently a few policies that may be able to address the issues that Sora poses, although they are far from comprehensive. California’s AB 459 mandates the clear labeling and identification of synthetic media in political contexts in order to reduce election-related disinformation. Similarly, AB 873 extends California’s privacy protections to include biometric data, potentially protecting against the use of a person's likeness without consent. </p>

        <p>While these policies mark early steps toward accountability, they remain restricted and reactive, falling short of addressing the full scale and novelty of potential issues raised by Sora. Future iterations of similar policies could benefit from more general AI declaration mandates, bans on the use of certain likenesses, and efforts on a federal level to address the issue. Generative AI’s capabilities have rapidly progressed since their roots in the GAN era and earlier. It’s time that policy progresses along with it. </p>
    </div>
    </body>
</html>

