---
layout: article
title: "How OpenAI’s Sora Tests Privacy, Creativity, and Policy"
date: 2025-11-01
author: Tarunya Dharmarajan
author_bio: "Tarunya Dharmarajan is a first-year at New York University studying Computer Science, AI, and Public Policy. She currently serves as cofounder and Director of Events/Logistics at PETAL, and hopes to become a technology lawyer in the future." 
excerpt: "Sora poses some serious challenges in real-world application, highlighting the need for more adaptive and comprehensive legislation."
tags: [research, ai]
---

In the realm of generative AI technologies, video generation has been one of the most remarkable yet simultaneously problematic innovations. Though it has become more popular in the past few years, AI video generation dates back to 2014, when generative adversarial networks (GANs) were first used for generating audio, video, and imagery. That early work was relatively rudimentary, but it has since been improved and expanded.

The most recent and revolutionary development in AI video generation is OpenAI’s Sora. Sora is advertised as producing far more realistic imagery than prior models, coupled with highly natural sound effects and dialogue. Like preceding models, Sora uses a text prompt to generate a video. Generation uses a diffusion-transformer pipeline that compresses videos into simplified representations, generates new content, then decompresses to a full visual form. Sora scales this process with more training data, producing clearer decompressions and more realistic output.

<div class="article-figure">
  <iframe src="https://openaiassets.blob.core.windows.net/$web/nf2/blog-final2/20250924_2154_New%20Video_simple_compose_01k5zkjk6cewmbdna01qtg293g.mp4"></iframe>
  <figcaption>Video from <a href="https://openai.com/index/sora-2/">OpenAI's launch of Sora</a></figcaption>
</div>

While Sora is a remarkable technical feat, it poses serious challenges in real-world application and highlights the need for more adaptive and comprehensive legislation. The model raises major concerns around generation of visual disinformation, particularly when hyperrealistic output is difficult to distinguish from genuine footage. Such disinformation can rapidly spread online and be used for political propaganda, falsified news, or fabricated speech.

<div class="article-figure">
  <iframe src="https://openaiassets.blob.core.windows.net/$web/nf2/blog-final2/Copy%20of%2020250925_2005_New%20Video_simple_compose_01k61zpe8yfshs06fb6e768v88.mp4"></iframe>
  <figcaption>Video from <a href="https://openai.com/index/sora-2/">OpenAI's launch of Sora</a></figcaption>
</div>

Sora’s improved understanding of body movement and motion physics makes its output more believable than that of predecessors. It also includes a “Cameo” feature that can generate a person’s likeness from reference videos, raising concerns about consent, misuse of biometric likenesses, and potential displacement of film-industry jobs.

A few policies begin to address these risks. California’s AB 459 mandates clear labeling of synthetic media in political contexts to reduce election-related disinformation. AB 873 extends California’s privacy protections to biometric data, offering some protection against use of a person's likeness without consent. These measures are early steps, but they are limited and reactive.

Future policy could include broader AI-declaration mandates, restrictions on use of certain likenesses without consent, and coordinated federal action. Generative AI has advanced rapidly since the GAN era; policy must progress alongside it to mitigate harms while preserving beneficial innovation.